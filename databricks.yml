# =============================================================================
# Databricks Asset Bundle (DAB) - Payment Analysis Platform
# =============================================================================
# This project is a Databricks Asset Bundle per the official docs:
#   https://docs.databricks.com/aws/en/dev-tools/bundles/
# Payment approval optimization: Smart Checkout, Reason Codes, Smart Retry.
# All parameters have defaults or are set at deployment (target/variables).
# Docs: docs/GUIDE.md, docs/DEPLOYMENT.md
#
# Deploy app: ./scripts/bundle.sh deploy [dev|prod]
# Required: catalog exists; app env LAKEBASE_* + DATABRICKS_WAREHOUSE_ID (see DEPLOYMENT.md).
# App resources/scopes: resources/fastapi_app.yml (sql-warehouse, jobs 1–7, user_api_scopes: sql, jobs, pipelines).
# =============================================================================

bundle:
  name: payment-analysis

# Prevent DAB from adding name_prefix to Unity Catalog schema names.
# In development mode, DAB auto-prefixes resource names (e.g. "dev_<user>_").
# We always use "payment_analysis" as the schema name, so skip the prefix to
# avoid DAB turning it into "dev_<user>_payment_analysis".
experimental:
  skip_name_prefix_for_schema: true

# Workspace root: sync and app use the same path (apps-cookbook / apx pattern).
# file_path = root_path so bundle sync uploads to root_path (no separate files/ copy); jobs and app run from root_path.
workspace:
  root_path: /Workspace/Users/${workspace.current_user.userName}/${var.workspace_folder}
  file_path: ${workspace.root_path}

# Resource modules. Order: UC → warehouse → pipelines → jobs → dashboards → app.
# Lakebase is required for UI CRUD (rules, experiments, incidents) and ML features.
# model_serving.yml — uncomment after Step 5 (Train ML Models) and decline_analyst registered so 5 endpoints exist in UC.
# Vector Search: create manually from resources/vector_search.yml.
# Execution order for jobs (Setup & Run): see docs/DEPLOYMENT.md and Setup & Run in the app.
#
# Dashboards: resources/dashboards.yml is included so deploy updates existing dashboards in place
# (same display_name + parent_path). Run prepare before deploy so .build/dashboards/*.lvdash.json exist.
include:
  - resources/unity_catalog.yml
  - resources/lakebase.yml
  - resources/pipelines.yml
  - resources/sql_warehouse.yml
  - resources/ml_jobs.yml
  - resources/agents.yml
  - resources/streaming_simulator.yml
  - resources/genie_spaces.yml
  - resources/dashboards.yml
  - resources/model_serving.yml
  - resources/fastapi_app.yml

# -----------------------------------------------------------------------------
# Bundle variables (override via --var, BUNDLE_VAR_*, or target variables)
# -----------------------------------------------------------------------------
variables:
  catalog:
    description: Unity Catalog name for all data, volumes, and ML models
    default: ahs_demos_catalog
  environment:
    description: Deployment environment identifier (e.g. dev, prod); used in resource names and tags
    default: dev
  schema:
    description: Unity Catalog schema name. Always "payment_analysis" (same in dev and prod).
    default: payment_analysis
  warehouse_id:
    description: SQL Warehouse ID for dashboards and SQL tasks; in dev, set from deployed warehouse resource
    default: "148ccb90800933a1"
  # Lakebase (managed Postgres) - required for UI CRUD and ML features
  # If the bundle does not create the project (e.g. "unknown field: postgres_project"), create a Lakebase project in Compute → Lakebase, then set these three vars to your project/branch/endpoint IDs (e.g. --var lakebase_project_id=my-project --var lakebase_branch_id=main --var lakebase_endpoint_id=primary).
  lakebase_project_id:
    description: "Lakebase Autoscaling project ID. Used by job 1 lakebase_data_init. Must match an existing project (create in Compute → Lakebase if needed)."
    default: payment-analysis-db
  lakebase_branch_id:
    description: "Lakebase Autoscaling branch ID (e.g. production, main). Must match a branch in your project."
    default: production
  lakebase_endpoint_id:
    description: "Lakebase Autoscaling endpoint ID (e.g. primary). Must match an endpoint in your project."
    default: primary
  lakebase_instance_name:
    description: "(Unused) Lakebase Autoscaling only; kept for backward compatibility."
    default: ""
  lakebase_capacity:
    description: Lakebase instance capacity (CU_1, CU_2, CU_4, CU_8)
    default: CU_1
  lakebase_uc_catalog_name:
    description: Unity Catalog catalog name for Lakebase registration
    default: payment_analysis_lakebase
  lakebase_database_name:
    description: Postgres database name inside the Lakebase instance
    default: payment_analysis
  workspace_folder:
    description: Workspace folder name for bundle files (notebooks, dashboards, app). Must match repo/deploy path (e.g. payment-analysis).
    default: payment-analysis
  # Genie space ID for app resource binding. Default empty; do not add genie-space to app resources in resources/fastapi_app.yml unless this is set (empty space_id causes deploy to fail).
  genie_space_id:
    description: "Genie space ID (e.g. UUID of 'Payment Analytics' from Genie UI). Set for genie-space app resource (empty may cause deploy to fail)."
    default: "01f10700a35c1756a892406b5bab0b67"
  pipelines_development:
    description: "If true, pipelines use development mode (e.g. lower cost). Set false for prod."
    default: true

# -----------------------------------------------------------------------------
# Sync: paths uploaded to workspace for job/pipeline execution and app
# -----------------------------------------------------------------------------
sync:
  include:
    - .build
    - dashboards
    - src/payment_analysis/__dist__   # UI build output (created by artifacts.default build); required for app web UI
    - src/payment_analysis/ml
    - src/payment_analysis/streaming
    - src/payment_analysis/transform
    - src/payment_analysis/agents
    - src/payment_analysis/genie
    - src/payment_analysis/vector_search
    - scripts
    - resources/dashboards
  exclude:
    - "**/__pycache__"
    - "**/*.pyc"
    - "**/node_modules"
    - "**/.env"
    - "**/.env.*"

# Build artifact for app deployment (served at /)
artifacts:
  default:
    build: uv run apx build

# -----------------------------------------------------------------------------
# Targets: dev (development) and prod (production)
# -----------------------------------------------------------------------------
targets:
  dev:
    # NOTE: "mode: development" is NOT used because it forces a name_prefix
    # (e.g. "[dev ariel_hdez]") on every resource and schema. Instead, we
    # replicate the development-mode presets manually with no name prefix.
    default: true
    variables:
      environment: dev
      schema: payment_analysis
      warehouse_id: ${resources.sql_warehouses.payment_analysis_warehouse.id}
      # Lakebase Autoscaling: required for job 1 (create_lakebase_autoscaling + lakebase_data_init)
      lakebase_project_id: payment-analysis-db
      lakebase_branch_id: production
      lakebase_endpoint_id: primary
    presets:
      pipelines_development: true
      jobs_max_concurrent_runs: 1
      trigger_pause_status: PAUSED

  prod:
    mode: production
    workspace:
      root_path: /Workspace/Users/${workspace.current_user.userName}/.bundle/${bundle.name}/${bundle.target}
    variables:
      environment: prod
      catalog: prod_catalog
      schema: payment_analysis
      warehouse_id: ${resources.sql_warehouses.payment_analysis_warehouse.id}
      pipelines_development: false
    presets:
      name_prefix: "[PROD] "
      pipelines_development: false
    # run_as is not set here: dashboards and apps do not support run_as different from owner.
    # To run jobs/pipelines as a service principal in prod, set run_as on each job in resources/ml_jobs.yml (or pipelines.yml).
    permissions:
      - level: CAN_VIEW
        group_name: data-analysts
      - level: CAN_MANAGE
        group_name: data-engineers
      # Include deployer so CAN_MANAGE applies when deploying as current user
      - level: CAN_MANAGE
        user_name: ${workspace.current_user.userName}
