# Databricks App execution (app.yaml). Required at project root.
# Docs: https://docs.databricks.com/aws/en/dev-tools/databricks-apps/app-runtime
# App definition (resources, bindings): resources/fastapi_app.yml. When deployed, the platform runs this in source_code_path and proxies traffic to the app.
# Environment variables: defined below in env (not in Compute → Apps → Edit UI). Redeploy bundle to apply changes.
#
# Authorization (two identity models):
#   User auth (OBO): open from Compute → Apps → payment-analysis; platform forwards X-Forwarded-Access-Token.
#     Scopes (user_api_scopes in fastapi_app.yml): sql, serving.serving-endpoints, dashboards.genie
#   App auth (SP): DATABRICKS_CLIENT_ID/SECRET injected by platform. Used for Lakebase, background tasks, app_config.
#
# Platform-injected env: DATABRICKS_WAREHOUSE_ID (from sql-warehouse binding), DATABRICKS_CLIENT_ID, DATABRICKS_CLIENT_SECRET.
#
# WORKSPACE PORTABILITY: Dashboard and Genie IDs below are workspace-specific.
# On a new workspace, either:
#   (a) Leave dashboard IDs empty — the backend auto-discovers them from the workspace API, OR
#   (b) After running Job 4 (Deploy Dashboards), update the IDs below and redeploy.
# The Genie space ID must be set after creating the space in the target workspace.
command:
  - uvicorn
  - payment_analysis.backend.app:app
  - --host
  - "0.0.0.0"
  - --port
  - "8000"
env:
  - name: PYTHONPATH
    value: src
  # Lakebase Autoscaling (example defaults; override via bundle vars or workspace)
  - name: LAKEBASE_PROJECT_ID
    value: payment-analysis-db
  - name: LAKEBASE_BRANCH_ID
    value: production
  - name: LAKEBASE_ENDPOINT_ID
    value: primary
  # Genie space ID for natural language data queries (Genie Assistant floating dialog).
  # When set, POST /api/agents/chat uses Databricks Genie Conversation API.
  # Set this after creating the Genie space in the target workspace, or leave empty to disable Genie.
  - name: GENIE_SPACE_ID
    value: "01f10700a35c1756a892406b5bab0b67"
  # ResponsesAgent endpoint on Model Serving (with UC tools).
  # Primary path for AI Chat (Path 1). Falls through to AI Gateway Opus 4.6 (Path 2) if failing.
  # This is the PaymentAnalysisAgent built in this solution with 10 UC tools + python_exec.
  - name: ORCHESTRATOR_SERVING_ENDPOINT
    value: "payment-response-agent"
  # Foundation model endpoint for AI Gateway orchestrator chat (Path 2 fallback).
  # Uses Claude Opus 4.6 — the strongest reasoning model for complex payment analysis.
  - name: LLM_ENDPOINT
    value: "databricks-claude-opus-4-6"
  # Balanced-tier model for Genie Assistant data questions (Sonnet — fast, cost-effective).
  - name: LLM_ENDPOINT_GENIE
    value: "databricks-claude-sonnet-4-5"
  # Job 6 ID — set explicitly so orchestrator chat doesn't need to list all workspace jobs.
  - name: DATABRICKS_JOB_ID_ORCHESTRATOR_AGENT
    value: "322421284086051"
  # Lakeview dashboard IDs — leave empty for auto-discovery from workspace API.
  # If auto-discovery is too slow or unreliable, set explicitly after Job 4 deploys dashboards.
  # Updated: 2026-02-05 - Verified against actual dashboards in workspace
  - name: DASHBOARD_ID_DATA_QUALITY
    value: "01f10c630ab414f18fc5a9d5f5db58a7"
  - name: DASHBOARD_ID_ML_OPTIMIZATION
    value: "01f10c630ac01742adbe0ecab4d3dde7"
  - name: DASHBOARD_ID_EXECUTIVE_TRENDS
    value: "01f10c630abf198a95ac2df801f29ac5"
