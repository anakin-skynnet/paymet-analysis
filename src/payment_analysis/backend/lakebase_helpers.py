"""Shared Lakebase Autoscaling utilities.

Centralises endpoint name construction, host resolution, and credential
generation so every consumer uses the correct SDK field paths.

SDK reference:
  - Host: ``endpoint.status.hosts.host`` (object, not a list)
  - State: ``endpoint.status.current_state``
  - Docs: https://docs.databricks.com/aws/en/oltp/projects/manage-computes
"""

from __future__ import annotations

import re
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from databricks.sdk import WorkspaceClient


# ---------------------------------------------------------------------------
# Resource naming
# ---------------------------------------------------------------------------

def build_endpoint_name(project_id: str, branch_id: str, endpoint_id: str) -> str:
    """Build the hierarchical endpoint resource name expected by the Postgres API.

    Format: ``projects/{project_id}/branches/{branch_id}/endpoints/{endpoint_id}``
    """
    return f"projects/{project_id}/branches/{branch_id}/endpoints/{endpoint_id}"


# ---------------------------------------------------------------------------
# Endpoint discovery
# ---------------------------------------------------------------------------

def discover_endpoint_name(
    ws: WorkspaceClient,
    project_id: str,
    branch_id: str,
    endpoint_id: str,
) -> str:
    """Discover the actual endpoint name on the given branch.

    Lakebase auto-generates endpoint names (e.g. ``ep-broad-forest-xxx``) when a
    project is created.  The configured ``endpoint_id`` (e.g. ``'primary'``) may
    not match the actual name.  Tries the configured name first; if not found,
    lists endpoints on the branch and returns the first one.

    Raises ``ValueError`` if no endpoints exist on the branch.
    """
    from databricks.sdk.errors import NotFound

    postgres_api = _get_postgres_api(ws)
    configured_name = build_endpoint_name(project_id, branch_id, endpoint_id)

    try:
        postgres_api.get_endpoint(name=configured_name)
        return configured_name
    except NotFound:
        pass

    # List endpoints on the branch and pick the first one
    branch_path = f"projects/{project_id}/branches/{branch_id}"
    endpoints = list(postgres_api.list_endpoints(parent=branch_path))
    if endpoints:
        return getattr(endpoints[0], "name", configured_name)

    raise ValueError(
        f"No endpoints found on branch {branch_path!r}. "
        "Run Job 1 (create_lakebase_autoscaling) or create an endpoint in Compute → Lakebase."
    )


# ---------------------------------------------------------------------------
# Host resolution
# ---------------------------------------------------------------------------

def resolve_endpoint_host(
    ws: WorkspaceClient,
    endpoint_name: str,
) -> str:
    """Fetch the endpoint and return its connection host.

    Raises ``ValueError`` if the endpoint has no host assigned (e.g. compute
    is suspended or still starting).

    Per the SDK docs the host lives at ``endpoint.status.hosts.host`` (the
    ``hosts`` attribute is an object, **not** a list).
    """
    postgres_api = _get_postgres_api(ws)
    endpoint = postgres_api.get_endpoint(name=endpoint_name)
    host = _extract_host(endpoint)
    if not host:
        raise ValueError(
            f"Lakebase endpoint {endpoint_name!r} has no host assigned. "
            "Ensure the compute is running (Compute → Lakebase)."
        )
    return host


def _extract_host(endpoint: object) -> str | None:
    """Extract connection host from an Endpoint object (safe attribute access)."""
    status = getattr(endpoint, "status", None)
    if status is None:
        return None
    hosts_obj = getattr(status, "hosts", None)
    return getattr(hosts_obj, "host", None) if hosts_obj else None


def get_endpoint_state(endpoint: object) -> str:
    """Extract ``current_state`` from an Endpoint object, falling back to ``state``."""
    status = getattr(endpoint, "status", None)
    if status is None:
        return "UNKNOWN"
    return (
        getattr(status, "current_state", None)
        or getattr(status, "state", None)
        or "UNKNOWN"
    )


# ---------------------------------------------------------------------------
# Postgres API guard
# ---------------------------------------------------------------------------

def _get_postgres_api(ws: WorkspaceClient):
    """Return ``ws.postgres`` or raise a clear error."""
    api = getattr(ws, "postgres", None)
    if api is None:
        raise AttributeError(
            "WorkspaceClient has no attribute 'postgres'. "
            "Lakebase Autoscaling requires databricks-sdk>=0.86.0 and a workspace with Lakebase enabled."
        )
    return api


# ---------------------------------------------------------------------------
# Schema-name validation (for raw SQL in notebooks / lakebase_config)
# ---------------------------------------------------------------------------

_SAFE_IDENTIFIER_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")


def validate_pg_identifier(name: str, label: str = "identifier") -> str:
    """Validate *name* as a safe Postgres identifier for use in quoted SQL.

    Prevents SQL injection when building ``"schema".table`` strings.
    Raises ``ValueError`` on invalid input; returns the validated name.
    """
    if not name or not _SAFE_IDENTIFIER_RE.match(name):
        raise ValueError(
            f"Invalid Postgres {label}: {name!r}. "
            "Must be 1-128 chars: letters, digits, underscores; must start with a letter or underscore."
        )
    return name
