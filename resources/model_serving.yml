# =============================================================================
# Model Serving Endpoints
# =============================================================================
# Endpoints created/updated PROGRAMMATICALLY by Jobs 5 and 6:
#   - Job 5 (train_models.py): creates/updates 4 ML model endpoints
#   - Job 6 (register_responses_agent.py): creates/updates payment-response-agent
#
# This file manages AI Gateway configurations (rate limits, usage tracking) via DAB
# for the 4 ML endpoints. The agent endpoint (payment-response-agent) is managed by
# Job 6's register_responses_agent task.
#
# Tiered LLM strategy:
#   ResponsesAgent → Sonnet 4.5 (balanced speed/quality for multi-turn tool calling)
#   AI Gateway fallback → Opus 4.6 (strongest reasoning, single-turn)
#   Agent Framework → Opus 4.6 (orchestrator) + Sonnet 4.5 (specialists)
# =============================================================================

resources:
  model_serving_endpoints:
    # Predicts transaction approval probability
    approval_propensity_endpoint:
      name: "approval-propensity"
      config:
        served_entities:
          - entity_name: "${var.catalog}.${var.schema}.approval_propensity_model"
            entity_version: "${var.ml_model_version}"
            workload_size: "Small"
            scale_to_zero_enabled: true
            workload_type: "CPU"
            environment_vars: { ENABLE_MLFLOW_TRACING: "true" }
        traffic_config:
          routes: [{ served_model_name: "approval_propensity_model-${var.ml_model_version}", traffic_percentage: 100 }]
      ai_gateway:
        rate_limits: [{ key: "user", renewal_period: "minute", calls: 100 }]
        usage_tracking_config: { enabled: true }

    # Fraud risk scoring
    risk_scoring_endpoint:
      name: "risk-scoring"
      config:
        served_entities:
          - entity_name: "${var.catalog}.${var.schema}.risk_scoring_model"
            entity_version: "${var.ml_model_version}"
            workload_size: "Small"
            scale_to_zero_enabled: true
            workload_type: "CPU"
            environment_vars: { ENABLE_MLFLOW_TRACING: "true" }
        traffic_config:
          routes: [{ served_model_name: "risk_scoring_model-${var.ml_model_version}", traffic_percentage: 100 }]
      ai_gateway:
        rate_limits: [{ key: "user", renewal_period: "minute", calls: 100 }]
        usage_tracking_config: { enabled: true }

    # Optimal payment route recommendation
    smart_routing_endpoint:
      name: "smart-routing"
      config:
        served_entities:
          - entity_name: "${var.catalog}.${var.schema}.smart_routing_policy"
            entity_version: "${var.ml_model_version}"
            workload_size: "Small"
            scale_to_zero_enabled: true
            workload_type: "CPU"
            environment_vars: { ENABLE_MLFLOW_TRACING: "true" }
        traffic_config:
          routes: [{ served_model_name: "smart_routing_policy-${var.ml_model_version}", traffic_percentage: 100 }]
      ai_gateway:
        rate_limits: [{ key: "user", renewal_period: "minute", calls: 200 }]
        usage_tracking_config: { enabled: true }

    # Retry success likelihood and recovery
    smart_retry_endpoint:
      name: "smart-retry"
      config:
        served_entities:
          - entity_name: "${var.catalog}.${var.schema}.smart_retry_policy"
            entity_version: "${var.ml_model_version}"
            workload_size: "Small"
            scale_to_zero_enabled: true
            workload_type: "CPU"
            environment_vars: { ENABLE_MLFLOW_TRACING: "true" }
        traffic_config:
          routes: [{ served_model_name: "smart_retry_policy-${var.ml_model_version}", traffic_percentage: 100 }]
      ai_gateway:
        rate_limits: [{ key: "user", renewal_period: "minute", calls: 200 }]
        usage_tracking_config: { enabled: true }
