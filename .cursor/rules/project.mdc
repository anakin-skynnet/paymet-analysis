---
alwaysApply: true
---

# Cursor Agent Rules

**Unified agent context:** For solution scope, MCP reference, agent framework, and common requests, see [AGENTS.md](../../AGENTS.md). For technical details, see [docs/REFERENCE.md](../../docs/REFERENCE.md). The rules below align with AGENTS.md.

# Do's and Don'ts
- **Deploy prompt:** When the user sends a "deploy" or "redeploy" prompt, **always ask** before running: "Are you deploying the app or the rest of the resources?" Then run the matching command: **rest of resources** → `./scripts/bundle.sh deploy [target]` (phase 1: all except the App; then user runs jobs 5 and 6 and later "deploy app"); **app** → `./scripts/bundle.sh deploy app [target]` (phase 2: validate and deploy the App with model serving and all resources uncommented).
- OpenAPI client is generated at build time; don't manually regenerate.
- Prefer running apx related commands via MCP server if it's available.
- Use the apx MCP `search_registry_components` and `add_component` tools to find and add shadcn/ui components.
- When using the API calls on the frontend, use error boundaries to handle errors.
- Run `apx dev check` command (via CLI or MCP) to check for errors in the project code after making changes.
- If agent has access to native browser tool, use it to verify changes on the frontend. If such tool is not present or is not working, use playwright MCP to automate browser actions (e.g. screenshots, clicks, etc.).
- **Databricks SDK:** Use the apx MCP `docs` tool to search Databricks SDK documentation instead of guessing or hallucinating API signatures.
- Always use Databricks latest features, releases and naming
- When mentioning an APP in a prompt, always confirm if it is referring to a Databricks APP
- Do not update dependencies and packages if not instructed

## Package Management
- **Frontend:** Bun might not be present on user's $PATH. It's recommended to use prebundled bun (e.g., `uv run apx bun install` or `uv run apx bun add <dependency>`), unless user explicitly stated otherwise.
- **Python:** Always use `uv` (never `pip`)

## Component Management
- **Finding components:** Use MCP `search_registry_components` to search for available shadcn/ui components
- **Adding components:** Use MCP `add_component` or CLI `uv run apx components add <component> --yes` to add components
- **Component location:** If component was added to a wrong location (e.g. stored into `src/components` instead of `src/payment_analysis/ui/components`), move it to the proper folder
- **Component organization:** Prefer grouping components by functionality rather than by file type (e.g. `src/payment_analysis/ui/components/chat/`)

## Project Structure
Full-stack app: `src/payment_analysis/ui/` (React + Vite) and `src/payment_analysis/backend/` (FastAPI). Backend serves frontend at `/` and API at `/api`. API client auto-generated from OpenAPI schema.


## Models & API
- **3-model pattern:** `Entity` (DB), `EntityIn` (input), `EntityOut` (output)
- **API routes must have:** `response_model` and `operation_id` for client generation

## Frontend Rules
- **Routing:** `@tanstack/react-router` (routes in `src/payment_analysis/ui/routes/`)
- **Data fetching:** Always use `useXSuspense` hooks with `Suspense` and `Skeleton` components
- **Pattern:** Render static elements immediately, fetch API data with suspense
- **Components:** Use shadcn/ui, add to `src/payment_analysis/ui/components/`
- **Data access:** Use `selector()` function for clean destructuring (e.g., `const {data: profile} = useProfileSuspense(selector())`)

## Development Commands

App is deployed to Databricks (not run locally). Use these for validation and deployment:

**Check for errors** (TypeScript, Python linting):
```bash
uv run apx dev check
```

**Verify all** (build, backend smoke test, dashboard assets, bundle validate):
```bash
./scripts/bundle.sh verify [dev|prod]
```

**Build for production:**
```bash
uv run apx build
```

**Two-phase deploy** (run from repo root):

- **Phase 1 — rest of resources (no app):** `./scripts/bundle.sh deploy [dev|prod]` or `./scripts/bundle.sh redeploy [dev|prod]`. Deploys jobs, pipelines, dashboards, etc.; outputs: "all resources deployed except the App. Run jobs 5 and 6. After completion, write the prompt \"deploy app\"". Always validates that the app can be deployed with all dependencies and resources when you run phase 2.
- **Phase 2 — app (after jobs 5 and 6):** `./scripts/bundle.sh deploy app [dev|prod]`. Validates app dependencies, uncomments model_serving and serving bindings, deploys the App with all resources assigned and uncommented.

When the user says "deploy" or "redeploy", always ask: "Are you deploying the app or the rest of the resources?" then run the matching phase.

Before any `databricks bundle` command (validate, deploy, run), ensure dashboard files exist: run `uv run python scripts/dashboards.py prepare` (or with `--catalog`/`--schema` for prod)—otherwise you get "failed to read serialized dashboard from file_path .build/dashboards/...."

## MCP Tools Reference

**Full list and setup:** See [.cursor/MCP.md](../../.cursor/MCP.md) for all configured servers (apx, shadcn, playwright, databricks) and how they connect to backend/Databricks.

When the **apx** MCP server is available, use these tools:

| Tool | Description |
|------|-------------|
| `check` | Check project code for errors (runs tsc and ty checks in parallel) |
| `refresh_openapi` | Regenerate OpenAPI schema and API client |
| `search_registry_components` | Search shadcn registry components using semantic search |
| `add_component` | Add a component to the project |
| `docs` | Search Databricks SDK documentation for code examples and API references |
| `databricks_apps_logs` | Fetch logs from deployed Databricks app using Databricks CLI |
| `get_route_info` | Get code example for using a specific API route |

**Databricks MCP** (when enabled and credentials set): list UC catalogs/schemas/tables, describe tables with lineage, execute SQL. Use for development-time exploration; the app serves data via the FastAPI backend.
